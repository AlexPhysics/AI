{"cells":[{"cell_type":"markdown","metadata":{"id":"iFlutahBZ45L"},"source":["# =Documentation="]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1681220553240,"user":{"displayName":"Costrița Alexandru","userId":"07418408971341455737"},"user_tz":-120},"id":"wZWCnAXoaQRV"},"outputs":[],"source":["#Python : https://www.python.org/downloads"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1681220553241,"user":{"displayName":"Costrița Alexandru","userId":"07418408971341455737"},"user_tz":-120},"id":"ZDeCjeV5aNsb"},"outputs":[],"source":["#EdgeGPT: https://github.com/acheong08/EdgeGPT"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1681220553243,"user":{"displayName":"Costrița Alexandru","userId":"07418408971341455737"},"user_tz":-120},"id":"ANSkupytaNjk"},"outputs":[],"source":["#WhisperAi from openAi: https://github.com/openai/whisper"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1681220553244,"user":{"displayName":"Costrița Alexandru","userId":"07418408971341455737"},"user_tz":-120},"id":"x3Rba_FzaaKU"},"outputs":[],"source":["#SpeechRecognition: https://pypi.org/project/SpeechRecognition/"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1681220553245,"user":{"displayName":"Costrița Alexandru","userId":"07418408971341455737"},"user_tz":-120},"id":"Ilgt9GvdaaBl"},"outputs":[],"source":["#Polly (AWS): https://aws.amazon.com/polly/"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1681220553246,"user":{"displayName":"Costrița Alexandru","userId":"07418408971341455737"},"user_tz":-120},"id":"PpUC9uO1awx2"},"outputs":[],"source":["#OpenAI: https://pypi.org/project/openai/"]},{"cell_type":"markdown","metadata":{"id":"xCr1iI5fZz_S"},"source":["# Installing libraries\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZVs_0sloaGjg"},"outputs":[],"source":["#Install python 3.10+"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fvOaJevkV7d4"},"outputs":[],"source":["#Install EdgeGPT to use bing API's: "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ekog90XXV7d4","tags":[]},"outputs":[],"source":["pip install EdgeGPT --upgrade"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W-zEid2kV7d5"},"outputs":[],"source":["#Install OpenAI Whisper for transcribing audio->text"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yllfdjVGV7d5"},"outputs":[],"source":["pip install git+https://github.com/openai/whisper.git "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zKQ4KCqEV7d5"},"outputs":[],"source":["pip install --upgrade --no-deps --force-reinstall git+https://github.com/openai/whisper.git"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pw2mq_TOV7d5"},"outputs":[],"source":["#Install the Speech Recognition library for recording microphone input"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KE3-8v2qV7d6"},"outputs":[],"source":["pip install SpeechRecognition"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZVTpYtnFV7d6"},"outputs":[],"source":["#To test what voice fits better you have to create an AWS account. \n","#Also in the code in the synthesize_speech function the voice can be changed.\n","#Install the boto3 library to access AWS services (AWS Polly-neural engine to generate the text-to-speech voice)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7bxUAw_qV7d6"},"outputs":[],"source":["pip install boto3"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oew6aYVDV7d6"},"outputs":[],"source":["#Install the pydub library to play the mp3 file"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"owzVrqm0V7d6"},"outputs":[],"source":["pip install pydub"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KMwuW_RPuVws"},"outputs":[],"source":["#Install the pyaudio to play the mp3 audio aswell"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Dw3JYPyZuVUb"},"outputs":[],"source":["pip install pyaudio"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6NVB_XNPV7d7"},"outputs":[],"source":["#Install openAI"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WE0h_GRhV7d7"},"outputs":[],"source":["pip install openai"]},{"cell_type":"markdown","metadata":{"id":"pqnYfmWwZn7c"},"source":["# Small parametrization"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jC4B2swRV7d7"},"outputs":[],"source":["#In order to use openAI API's you need to get one from here:\n","#https://platform.openai.com/account/api-keys"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zpV2uOHYV7d7"},"outputs":[],"source":["#Copy it and paste inside the code that you will find below:\n","#openai.api_key = \"[paste your OpenAI API key here]\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X765-6O8V7d8"},"outputs":[],"source":["#Install the cookie editor extension for Microsoft Edge(since bing can function only with Edge)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UIct9f5FV7d8"},"outputs":[],"source":["#https://microsoftedge.microsoft.com/addons/detail/cookieeditor/neaplmfkghagebokkhpjpoebhdledlfi?refid=bingshortanswers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E9IERL4jV7d8"},"outputs":[],"source":["#FYI that's the Bing chat AI: https://www.bing.com/search?form=MY02AE&OCID=MY02AE&pl=launch&q=Bing+AI&showconv=1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OxvivfchV7d8"},"outputs":[],"source":["#Go to bing.com\n","#Open the extension\n","#Click \"Export\" on the bottom right, then \"Export as JSON\" (This saves your cookies to clipboard)\n","#Paste your cookies into a file cookies.json"]},{"cell_type":"markdown","metadata":{"id":"tPwCw3ieZfTU"},"source":["# The .py code"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pGmICn3RbB5K"},"outputs":[],"source":["#This is a Python voice assistant that takes two different wake words. \n","#One for prompting Bing AI using EdgeGPT (Bing) and the other will prompt the GPT-3.5-Turbo API (Jarvis). \n","#For transcribing this program implements OpenAI Whisper locally. Text-to-speech is done with AWS Polly."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AcBcZO3wV7d9"},"outputs":[],"source":["import openai\n","import asyncio\n","import re\n","import whisper\n","#import boto3\n","import pydub\n","import playsound\n","from gtts import gTTS\n","import random\n","from pydub import playback\n","import speech_recognition as sr\n","from EdgeGPT import Chatbot, ConversationStyle\n","\n","# Initialize the OpenAI API\n","openai.api_key = \"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\"\n","\n","# Create a recognizer object and wake word variables\n","recognizer = sr.Recognizer()\n","\n","#Our Bing will be the virtual assistant that has updated data\n","BING_WAKE_WORD = \"alex\"\n","#Our Jarvis will be chatgpt\n","GPT_WAKE_WORD = \"jarvis\"\n","\n","def get_wake_word(phrase):\n","    if BING_WAKE_WORD in phrase.lower():\n","        return BING_WAKE_WORD\n","    elif GPT_WAKE_WORD in phrase.lower():\n","        return GPT_WAKE_WORD\n","    else:\n","        return None\n","    \n","def synthesize_speech(text, response):\n","    #for using google tts\n","    tts = gTTS(text=text, lang=\"en\")\n","    response = \"response.mp3\"\n","    tts.save(response)\n","\n","#==================================================================================================================#\n","    # For polly AWS\n","    # polly = boto3.client('polly', region_name='us-west-2')\n","    # response = polly.synthesize_speech(\n","    #     Text=text,\n","    #     OutputFormat='mp3',\n","    #     VoiceId='Salli',\n","    #     Engine='neural'\n","    # )\n","\n","    # with open(output_filename, 'wb') as f:\n","    #     f.write(response['AudioStream'].read())\n","#==================================================================================================================#\n","\n","def play_audio(file):\n","    sound = pydub.AudioSegment.from_file(file, format=\"mp3\")\n","    playback.play(sound)\n","\n","async def main():\n","    while True:\n","\n","        with sr.Microphone() as source:\n","            recognizer.adjust_for_ambient_noise(source)\n","            print(f\"Waiting for wake words 'Okay, Alex' or 'Okay, Jarvis'...\")\n","            while True:\n","                audio = recognizer.listen(source)\n","                try:\n","                    with open(\"audio.wav\", \"wb\") as f:\n","                        f.write(audio.get_wav_data())\n","                    # Use the preloaded tiny_model\n","                    model = whisper.load_model(\"tiny\")\n","                    result = model.transcribe(\"audio.wav\")\n","                    phrase = result[\"text\"]\n","                    print(f\"You said: {phrase}\")\n","\n","                    wake_word = get_wake_word(phrase)\n","                    if wake_word is not None:\n","                        break\n","                    else:\n","                        print(\"Not a wake word. Try again.\")\n","                except Exception as e:\n","                    print(\"Error transcribing audio: {0}\".format(e))\n","                    continue\n","\n","            help_word = [\"What can I help you with?\",\"Yes?\",\"What's up?\",\"How can I assist you?\",\"Can I do something for you?\",\n","                         \"What would please you today?\",\"Anything I can help you with today?\"]\n","            \n","            synthesize_speech(random.choice(help_word), 'response.mp3')\n","            play_audio('response.mp3')\n","            audio = recognizer.listen(source)\n","\n","            try:\n","                with open(\"audio_prompt.wav\", \"wb\") as f:\n","                    f.write(audio.get_wav_data())\n","                model = whisper.load_model(\"base\")\n","                result = model.transcribe(\"audio_prompt.wav\")\n","                user_input = result[\"text\"]\n","                print(f\"You said: {user_input}\")\n","            except Exception as e:\n","                print(\"Error transcribing audio: {0}\".format(e))\n","                continue\n","\n","            if wake_word == BING_WAKE_WORD:\n","                bot = Chatbot(cookiePath='cookies.json')\n","                response = await bot.ask(prompt=user_input, conversation_style=ConversationStyle.precise)\n","\n","                for message in response[\"item\"][\"messages\"]:\n","                    if message[\"author\"] == \"bot\":\n","                        bot_response = message[\"text\"]\n","\n","                bot_response = re.sub('\\[\\^\\d+\\^\\]', '', bot_response)\n","\n","                bot = Chatbot(cookiePath='cookies.json')\n","                response = await bot.ask(prompt=user_input, conversation_style=ConversationStyle.creative)\n","                # Select only the bot response from the response dictionary\n","                for message in response[\"item\"][\"messages\"]:\n","                    if message[\"author\"] == \"bot\":\n","                        bot_response = message[\"text\"]\n","                # Remove [^#^] citations in response\n","                bot_response = re.sub('\\[\\^\\d+\\^\\]', '', bot_response)\n","\n","            else:\n","                # Send prompt to GPT-3.5-turbo API\n","                response = openai.ChatCompletion.create(\n","                    model=\"gpt-3.5-turbo\",\n","                    messages=[\n","                        {\"role\": \"system\", \"content\":\n","                        \"You are a helpful assistant.\"},\n","                        {\"role\": \"user\", \"content\": user_input},\n","                    ],\n","                    temperature=0.5,\n","                    max_tokens=150,\n","                    top_p=1,\n","                    frequency_penalty=0,\n","                    presence_penalty=0,\n","                    n=1,\n","                    stop=[\"\\nUser:\"],\n","                )\n","\n","                bot_response = response[\"choices\"][0][\"message\"][\"content\"]\n","                \n","        print(\"\", bot_response)\n","        synthesize_speech(bot_response, 'response.mp3')\n","        play_audio('response.mp3')\n","\n","if __name__ == \"__main__\":\n","    asyncio.run(main())"]}],"metadata":{"colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
